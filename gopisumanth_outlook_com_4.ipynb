{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gopisumanth@outlook.com_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GopiSumanth/2015/blob/master/gopisumanth_outlook_com_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "breSw6aYkgd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "\n",
        "#x,y = make_classification(n_samples=10000, n_features=2, n_informative=2, n_redundant= 0, n_clusters_per_class=1, random_state=60)\n",
        "#X_train, X_test, y_train, y_test = train_test_split(x,y,stratify=y,random_state=42)\n",
        "\n",
        "# del X_train,X_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B12q4tY46G86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('iris.csv')\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, 4].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1jM4vjwkgeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "colors = {0:'red', 1:'blue'}\n",
        "plt.scatter(X_test[:,0], X_test[:,1],c=y_test)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJM-3AzTkgeQ",
        "colab_type": "text"
      },
      "source": [
        "# Implementing Custom RandomSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXpMFxiUkgeS",
        "colab_type": "text"
      },
      "source": [
        "<pre>\n",
        "def RandomSearchCV(x_train,y_train,classifier, param_range, folds):\n",
        "    # x_train: its numpy array of shape, (n,d)\n",
        "    # y_train: its numpy array of shape, (n,) or (n,1)\n",
        "    # classifier: its typically KNeighborsClassifier()\n",
        "    # param_range: its a tuple like (a,b) a < b\n",
        "    # folds: an integer, represents number of folds we need to devide the data and test our model\n",
        "    \n",
        "    \n",
        "    #1.generate 10 unique values(uniform random distribution) in the given range \"param_range\" and store them as \"params\" \n",
        "    # ex: if param_range = (1, 50), we need to generate 10 random numbers in range 1 to 50\n",
        "    #2.devide numbers ranging from  0 to len(X_train) into groups= folds\n",
        "    # ex: folds=3, and len(x_train)=100, we can devide numbers from 0 to 100 into 3 groups \n",
        "      group 1: 0-33, group 2:34-66, group 3: 67-100\n",
        "    #3.for each hyperparameter that we generated in step 1:\n",
        "        # and using the above groups we have created in step 2 you will do cross-validation as follows\n",
        "        \n",
        "        # first we will keep group 1+group 2 i.e. 0-66 as train data and group 3: 67-100 as test data, and find train and\n",
        "          test accuracies\n",
        "          \n",
        "        # second we will keep group 1+group 3 i.e. 0-33, 67-100 as train data and group 2: 34-66 as test data, and find\n",
        "          train and test accuracies\n",
        "          \n",
        "        # third we will keep group 2+group 3 i.e. 34-100 as train data and group 1: 0-33 as test data, and find train and\n",
        "          test accuracies\n",
        "        # based on the 'folds' value we will do the same procedure\n",
        "        \n",
        "        # find the mean of train accuracies of above 3 steps and store in a list \"train_scores\"\n",
        "        # find the mean of test accuracies of above 3 steps and store in a list \"test_scores\"\n",
        "    #4. return both \"train_scores\" and \"test_scores\"\n",
        "\n",
        "#5. call function RandomSearchCV(x_train,y_train,classifier, param_range, folds) and store the returned values into \"train_score\", and \"cv_scores\"\n",
        "#6. plot hyper-parameter vs accuracy plot as shown in reference notebook and choose the best hyperparameter\n",
        "#7. plot the decision boundaries for the model initialized with the best hyperparameter, as shown in the last cell of reference notebook\n",
        "\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYCIxGTPxSpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_10_random_numbers(a):\n",
        "  if a[0] < a[1]:\n",
        "    r = np.random.uniform(a[0],a[1],10)\n",
        "    r = list(r.astype(int))\n",
        "    r.sort()\n",
        "    if len(r) == len(set(r)):\n",
        "      return r\n",
        "    else:\n",
        "      r = generate_10_random_numbers(a)\n",
        "      return r\n",
        "  else:\n",
        "    print('Error: param_range: its a tuple like (a,b) a < b ')\n",
        "    return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5urPJIZ8cjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def divide_training_dataset_to_k_folds(x_train,y_train,folds):\n",
        "    temp = len(x_train)/folds\n",
        "    x_train = x_train.tolist()\n",
        "    y_train = y_train.tolist()\n",
        "    group = []\n",
        "    label = []\n",
        "    end = 0.0\n",
        "    while end < len(x_train):\n",
        "      group.append(x_train[int(end):int(end + temp)])\n",
        "      label.append(y_train[int(end):int(end + temp)])\n",
        "      end += temp\n",
        "    return group,label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX1CdOv_lvbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "def RandomSearchCV(x_train,y_train,classifier, param_range, folds):\n",
        "    # x_train: its numpy array of shape, (n,d)\n",
        "    # y_train: its numpy array of shape, (n,) or (n,1)\n",
        "    # classifier: its typically KNeighborsClassifier()\n",
        "    # param_range: its a tuple like (a,b) a < b\n",
        "    # folds: an integer, represents number of folds we need to devide the data and test our model\n",
        "\n",
        "\n",
        "    #1.generate 10 unique values(uniform random distribution) in the given range \"param_range\" and store them as \"params\" \n",
        "    # ex: if param_range = (1, 50), we need to generate 10 random numbers in range 1 to 50\n",
        "    \n",
        "    params = generate_10_random_numbers(param_range)\n",
        "    if params == 0:\n",
        "      exit()\n",
        "  \n",
        "  \n",
        "    #2.divide numbers ranging from  0 to len(X_train) into groups= folds\n",
        "    # ex: folds=3, and len(x_train)=100, we can devide numbers from 0 to 100 into 3 groups i.e: group 1: 0-33, group 2:34-66, group 3: 67-100\n",
        "    temp = len(x_train)/folds\n",
        "    temp = int(temp) \n",
        "    groups,labels = divide_training_dataset_to_k_folds(x_train,y_train,folds)\n",
        "    \n",
        "    #3.for each hyperparameter that we generated in step 1 and using the above groups we have created in step 2 you will do cross-validation as follows:\n",
        "\n",
        "    # first we will keep group 1+group 2 i.e. 0-66 as train data and group 3: 67-100 as test data, and find train and test accuracies\n",
        "\n",
        "    # second we will keep group 1+group 3 i.e. 0-33, 67-100 as train data and group 2: 34-66 as test data, and find train and test accuracies\n",
        "\n",
        "    # third we will keep group 2+group 3 i.e. 34-100 as train data and group 1: 0-33 as test data, and find train and test accuracies\n",
        "\n",
        "    # based on the 'folds' value we will do the same procedure\n",
        "\n",
        "    # find the mean of train accuracies of above 3 steps and store in a list \"train_scores\"\n",
        "    # find the mean of test accuracies of above 3 steps and store in a list \"test_scores\"  \n",
        "    train_scores = []\n",
        "    test_scores  = []    \n",
        "    for k in tqdm(params):\n",
        "      for i in range(folds):\n",
        "        trainscores_folds = []\n",
        "        testscores_folds  = []\n",
        "        X_train = [groups[iter] for iter in range(folds) if iter != i]\n",
        "        X_train = [j for sublist in X_train for j in sublist]\n",
        "        Y_train = [labels[iter] for iter in range(folds) if iter != i]\n",
        "        Y_train = [j for sublist in Y_train for j in sublist]\n",
        "        X_test  = groups[i]\n",
        "        Y_test  = labels[i]\n",
        "\n",
        "        classifier.n_neighbors = k\n",
        "        #print(np.asarray(Y_train))\n",
        "        classifier.fit(X_train,Y_train)\n",
        "        \n",
        "        Y_predicted = classifier.predict(X_test)\n",
        "\n",
        "        testscores_folds.append(accuracy_score(Y_test, Y_predicted))\n",
        "\n",
        "        Y_predicted = classifier.predict(X_train)\n",
        "        trainscores_folds.append(accuracy_score(Y_train, Y_predicted))\n",
        "      train_scores.append(np.mean(np.array(trainscores_folds)))\n",
        "      test_scores.append(np.mean(np.array(testscores_folds)))\n",
        "      \n",
        "    #4. return both \"train_scores\" and \"test_scores\"\n",
        "    return train_scores, test_scores,params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwNKYxjlyk1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. call function RandomSearchCV(x_train,y_train,classifier, param_range, folds) and store the returned values into \"train_score\", and \"cv_scores\"\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "classifier = KNeighborsClassifier()\n",
        "param_range = (1,50)\n",
        "folds = 3\n",
        "\n",
        "trainscores,testscores,params = RandomSearchCV(X_train,y_train,classifier, param_range, folds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMpXPgd64WVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 6. plot hyper-parameter vs accuracy plot as shown in reference notebook and choose the best hyperparameter\n",
        "plt.plot(params,trainscores, label='train cruve')\n",
        "plt.plot(params,testscores, label='test cruve')\n",
        "plt.title('Hyper-parameter VS accuracy plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxovBzLt7BMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj2uAxdB4gu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7. plot the decision boundaries for the model initialized with the best hyperparameter, as shown in the last cell of reference notebook\n",
        "# understanding this code line by line is not that importent \n",
        "def plot_decision_boundary(X1, X2, y, clf):\n",
        "        # Create color maps\n",
        "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
        "    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
        "\n",
        "    x_min, x_max = X1.min() - 1, X1.max() + 1\n",
        "    y_min, y_max = X2.min() - 1, X2.max() + 1\n",
        "    \n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02), np.arange(y_min, y_max, 0.02))\n",
        "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
        "    # Plot also the training points\n",
        "    plt.scatter(X1, X2, c=y, cmap=cmap_bold)\n",
        "    \n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "    plt.title(\"2-Class classification (k = %i)\" % (clf.n_neighbors))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mfw515tlEKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib.colors import ListedColormap\n",
        "neigh = KNeighborsClassifier(n_neighbors = 19)\n",
        "neigh.fit(X_train, y_train)\n",
        "plot_decision_boundary(X_train[:, 0], X_train[:, 1], y_train, neigh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQDPsPuZ7ULw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}